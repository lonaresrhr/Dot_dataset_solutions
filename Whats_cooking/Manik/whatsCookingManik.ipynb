{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import pipeline,ensemble,preprocessing,feature_extraction,metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.ingredients=train.ingredients.apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>plain flour ground pepper salt tomatoes ground...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>eggs pepper salt mayonaise cooking oil green c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>black pepper shallots cornflour cayenne pepper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  romaine lettuce black olives grape tomatoes ga...\n",
       "1  southern_us  25693  plain flour ground pepper salt tomatoes ground...\n",
       "2     filipino  20130  eggs pepper salt mayonaise cooking oil green c...\n",
       "3       indian  22213                     water vegetable oil wheat salt\n",
       "4       indian  13162  black pepper shallots cornflour cayenne pepper..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(train.ingredients,train.cuisine, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classi(clf):\n",
    "    classifier=pipeline.Pipeline([\n",
    "        ('tfidf_vectorizer', feature_extraction.text.TfidfVectorizer(lowercase=True)),\n",
    "        ('rf_classifier', clf)\n",
    "    ])\n",
    "    classifier.fit(x_train, y_train)\n",
    "    accu_train = metrics.accuracy_score(y_train, classifier.predict(x_train))\n",
    "    accu_test = metrics.accuracy_score(y_test, classifier.predict(x_test))\n",
    "    return accu_train, accu_test, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Train Accuracy:  0.9687293755303436 Test Accuracy:  0.6272784412319296\n"
     ]
    }
   ],
   "source": [
    "a1, b1, model1 = classi(ensemble.RandomForestClassifier(n_estimators=5,n_jobs=-1))\n",
    "print(\"Random Forest Classifier Train Accuracy: \",a1,\"Test Accuracy: \",b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Train:  0.9997171501304252 Test:  0.6139534883720931\n"
     ]
    }
   ],
   "source": [
    "a1, b1, model1 = classi(DecisionTreeClassifier(random_state=0))\n",
    "print(\"DecisionTreeClassifier Train Accuracy: \",a1,\"Test Accuracy: \",b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Train:  0.7378295986674628  Test:  0.7094908862350723\n"
     ]
    }
   ],
   "source": [
    "a3, b3, model3 = classi(BernoulliNB())\n",
    "print(\"BernoulliNB Train: \",a3,\" Test: \",b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train:  0.8472610704296175 Test:  0.7829038340666248\n"
     ]
    }
   ],
   "source": [
    "a5, b5, model5 = classi(SVC(kernel='linear'))\n",
    "print(\"SVM Train: \",a5,\"Test: \",b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/manik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Train:  0.8084792105345863 Test:  0.771213073538655\n"
     ]
    }
   ],
   "source": [
    "a6, b6, model6 = classi(LogisticRegression())\n",
    "print(\"LogisticRegression Train: \",a6,\"Test: \",b6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_json('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['greek', 'southern_us', 'filipino', 'indian', 'jamaican',\n",
       "       'spanish', 'italian', 'mexican', 'chinese', 'british', 'thai',\n",
       "       'vietnamese', 'cajun_creole', 'brazilian', 'french', 'japanese',\n",
       "       'irish', 'korean', 'moroccan', 'russian'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cusine=train1.cuisine.unique()\n",
    "cusine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = train1.groupby('cuisine')\n",
    "x=[grp.get_group(x) for x in grp.groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "braz = x[0].ingredients.tolist()\n",
    "british = x[1].ingredients.tolist()\n",
    "creole = x[2].ingredients.tolist()\n",
    "chinise = x[3].ingredients.tolist()\n",
    "filipino = x[4].ingredients.tolist()\n",
    "french = x[5].ingredients.tolist()\n",
    "greek = x[6].ingredients.tolist()\n",
    "indian = x[7].ingredients.tolist()\n",
    "irish = x[8].ingredients.tolist()\n",
    "italian = x[9].ingredients.tolist()\n",
    "jamaican = x[10].ingredients.tolist()\n",
    "japs = x[11].ingredients.tolist()\n",
    "korean = x[12].ingredients.tolist()\n",
    "mexican = x[13].ingredients.tolist()\n",
    "moroccan = x[14].ingredients.tolist()\n",
    "russian = x[15].ingredients.tolist()\n",
    "southUS = x[16].ingredients.tolist()\n",
    "spanish = x[17].ingredients.tolist()\n",
    "thai = x[18].ingredients.tolist()\n",
    "vietnamese = x[19].ingredients.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impIngridents(MainList):\n",
    "    ListAll = []\n",
    "    for sublist in MainList:\n",
    "        for item in sublist:\n",
    "            ListAll.append(item)\n",
    "    ctr = collections.Counter(ListAll)\n",
    "    mostCommon = [key for key, val in ctr.most_common(5)]\n",
    "    return mostCommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brazil: ['salt', 'onions', 'olive oil', 'lime', 'water']\n",
      "British: ['salt', 'all-purpose flour', 'butter', 'milk', 'eggs']\n",
      "creole: ['salt', 'onions', 'garlic', 'green bell pepper', 'butter']\n",
      "chinise: ['soy sauce', 'sesame oil', 'salt', 'corn starch', 'sugar']\n",
      "filipino: ['salt', 'garlic', 'water', 'onions', 'soy sauce']\n",
      "french: ['salt', 'sugar', 'all-purpose flour', 'unsalted butter', 'olive oil']\n",
      "greek: ['salt', 'olive oil', 'dried oregano', 'garlic cloves', 'feta cheese crumbles']\n",
      "indian: ['salt', 'onions', 'garam masala', 'water', 'ground turmeric']\n",
      "irish: ['salt', 'all-purpose flour', 'butter', 'onions', 'sugar']\n",
      "italian: ['salt', 'olive oil', 'garlic cloves', 'grated parmesan cheese', 'garlic']\n",
      "jamaican: ['salt', 'onions', 'water', 'garlic', 'ground allspice']\n",
      "japs: ['soy sauce', 'salt', 'mirin', 'sugar', 'water']\n",
      "korean: ['soy sauce', 'sesame oil', 'garlic', 'green onions', 'sugar']\n",
      "mexican: ['salt', 'onions', 'ground cumin', 'garlic', 'olive oil']\n",
      "moroccan: ['salt', 'olive oil', 'ground cumin', 'onions', 'ground cinnamon']\n",
      "russian: ['salt', 'sugar', 'onions', 'all-purpose flour', 'sour cream']\n",
      "southUS: ['salt', 'butter', 'all-purpose flour', 'sugar', 'large eggs']\n",
      "spanish: ['salt', 'olive oil', 'garlic cloves', 'extra-virgin olive oil', 'onions']\n",
      "thai: ['salt', 'olive oil', 'garlic cloves', 'extra-virgin olive oil', 'onions']\n",
      "vietnamese: ['salt', 'olive oil', 'garlic cloves', 'extra-virgin olive oil', 'onions']\n"
     ]
    }
   ],
   "source": [
    "print(\"Brazil:\",impIngridents(braz))\n",
    "print(\"British:\",impIngridents(british))\n",
    "print(\"creole:\",impIngridents(creole))\n",
    "print(\"chinise:\",impIngridents(chinise))\n",
    "print(\"filipino:\",impIngridents(filipino))\n",
    "print(\"french:\",impIngridents(french))\n",
    "print(\"greek:\",impIngridents(greek))\n",
    "print(\"indian:\",impIngridents(indian))\n",
    "print(\"irish:\",impIngridents(irish))\n",
    "print(\"italian:\",impIngridents(italian))\n",
    "print(\"jamaican:\",impIngridents(jamaican))\n",
    "print(\"japs:\",impIngridents(japs))\n",
    "print(\"korean:\",impIngridents(korean))\n",
    "print(\"mexican:\",impIngridents(mexican))\n",
    "print(\"moroccan:\",impIngridents(moroccan))\n",
    "print(\"russian:\",impIngridents(russian))\n",
    "print(\"southUS:\",impIngridents(southUS))\n",
    "print(\"spanish:\",impIngridents(spanish))\n",
    "print(\"thai:\",impIngridents(spanish))\n",
    "print(\"vietnamese:\",impIngridents(spanish))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
